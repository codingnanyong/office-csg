"""
TensorFlow Model Loading Test DAG
=================================
CNN Anomaly Classifier ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë”©ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í…ŒìŠ¤íŠ¸ DAG

í…ŒìŠ¤íŠ¸ í•­ëª©:
1. TensorFlow/Keras ìž„í¬íŠ¸ í™•ì¸
2. ëª¨ë¸ íŒŒì¼ ì¡´ìž¬ í™•ì¸
3. ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
4. ëª¨ë¸ ì •ë³´ ì¶œë ¥ (ìž…ë ¥/ì¶œë ¥ shape, ë ˆì´ì–´ ìˆ˜ ë“±)
5. ë”ë¯¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)

Schedule: ìˆ˜ë™ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
"""

import os
import logging
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
import tensorflow as tf
from tensorflow import keras
import numpy as np

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Configuration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MODEL_PATH = "/opt/airflow/models/cnn_anomaly_classifier.h5"

DEFAULT_ARGS = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=1),
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test Functions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_tensorflow_import(**kwargs) -> dict:
    """TensorFlow/Keras ìž„í¬íŠ¸ í…ŒìŠ¤íŠ¸"""
    logging.info("=" * 60)
    logging.info("1ï¸âƒ£ TensorFlow/Keras ìž„í¬íŠ¸ í…ŒìŠ¤íŠ¸")
    logging.info("=" * 60)
    
    try:
        logging.info(f"âœ… TensorFlow ë²„ì „: {tf.__version__}")
        

        logging.info(f"âœ… Keras ë²„ì „: {keras.__version__}")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            logging.info(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {len(gpus)}ê°œ")
            for i, gpu in enumerate(gpus):
                logging.info(f"   GPU {i}: {gpu.name}")
        else:
            logging.info("â„¹ï¸ GPU ì‚¬ìš© ë¶ˆê°€ (CPU ëª¨ë“œ)")
        
        return {
            "status": "success",
            "tensorflow_version": tf.__version__,
            "keras_version": keras.__version__,
            "gpu_available": len(gpus) > 0,
            "gpu_count": len(gpus)
        }
    except ImportError as e:
        error_msg = f"âŒ TensorFlow/Keras ìž„í¬íŠ¸ ì‹¤íŒ¨: {str(e)}"
        logging.error(error_msg)
        raise ImportError(error_msg) from e


def check_model_file(**kwargs) -> dict:
    """ëª¨ë¸ íŒŒì¼ ì¡´ìž¬ ë° ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    logging.info("=" * 60)
    logging.info("2ï¸âƒ£ ëª¨ë¸ íŒŒì¼ í™•ì¸")
    logging.info("=" * 60)
    
    if not os.path.exists(MODEL_PATH):
        error_msg = f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {MODEL_PATH}"
        logging.error(error_msg)
        raise FileNotFoundError(error_msg)
    
    # íŒŒì¼ ì •ë³´
    file_size = os.path.getsize(MODEL_PATH)
    file_size_mb = file_size / (1024 * 1024)
    
    logging.info(f"âœ… ëª¨ë¸ íŒŒì¼ ì¡´ìž¬: {MODEL_PATH}")
    logging.info(f"   íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB ({file_size:,} bytes)")
    
    # ì½ê¸° ê¶Œí•œ í™•ì¸
    if not os.access(MODEL_PATH, os.R_OK):
        error_msg = f"âŒ ëª¨ë¸ íŒŒì¼ ì½ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}"
        logging.error(error_msg)
        raise PermissionError(error_msg)
    
    logging.info("âœ… ëª¨ë¸ íŒŒì¼ ì½ê¸° ê¶Œí•œ í™•ì¸ ì™„ë£Œ")
    
    return {
        "status": "success",
        "model_path": MODEL_PATH,
        "file_size_bytes": file_size,
        "file_size_mb": round(file_size_mb, 2),
        "readable": True
    }


def load_model(**kwargs) -> dict:
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    logging.info("=" * 60)
    logging.info("3ï¸âƒ£ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    logging.info("=" * 60)
    
    try:
        
        logging.info(f"ëª¨ë¸ ë¡œë”© ì‹œìž‘: {MODEL_PATH}")
        model = keras.models.load_model(MODEL_PATH)
        logging.info("âœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        logging.info("=" * 60)
        logging.info("ðŸ“Š ëª¨ë¸ ì •ë³´")
        logging.info("=" * 60)
        
        # ëª¨ë¸ ìš”ì•½
        logging.info("ëª¨ë¸ êµ¬ì¡°:")
        model.summary(print_fn=logging.info)
        
        # ìž…ë ¥/ì¶œë ¥ shape
        if hasattr(model, 'input_shape'):
            logging.info(f"ìž…ë ¥ Shape: {model.input_shape}")
        if hasattr(model, 'output_shape'):
            logging.info(f"ì¶œë ¥ Shape: {model.output_shape}")
        
        # ë ˆì´ì–´ ì •ë³´
        logging.info(f"ì´ ë ˆì´ì–´ ìˆ˜: {len(model.layers)}")
        logging.info("ë ˆì´ì–´ ëª©ë¡:")
        for i, layer in enumerate(model.layers):
            layer_type = type(layer).__name__
            layer_config = layer.get_config() if hasattr(layer, 'get_config') else {}
            logging.info(f"  [{i+1}] {layer_type}: {layer.name}")
            if hasattr(layer, 'output_shape'):
                logging.info(f"      Output Shape: {layer.output_shape}")
        
        # ëª¨ë¸ ì»´íŒŒì¼ ì •ë³´
        if hasattr(model, 'optimizer') and model.optimizer:
            logging.info(f"Optimizer: {type(model.optimizer).__name__}")
        if hasattr(model, 'loss'):
            logging.info(f"Loss: {model.loss}")
        if hasattr(model, 'metrics'):
            logging.info(f"Metrics: {model.metrics}")
        
        return {
            "status": "success",
            "model_loaded": True,
            "input_shape": str(model.input_shape) if hasattr(model, 'input_shape') else None,
            "output_shape": str(model.output_shape) if hasattr(model, 'output_shape') else None,
            "layer_count": len(model.layers),
            "layers": [type(layer).__name__ for layer in model.layers]
        }
        
    except Exception as e:
        error_msg = f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}"
        logging.error(error_msg)
        logging.exception("ìƒì„¸ ì—ëŸ¬ ì •ë³´:")
        raise Exception(error_msg) from e


def test_model_prediction(**kwargs) -> dict:
    """ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
    logging.info("=" * 60)
    logging.info("4ï¸âƒ£ ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ (ë”ë¯¸ ë°ì´í„°)")
    logging.info("=" * 60)
    
    try:

        # ëª¨ë¸ ë¡œë”©
        model = keras.models.load_model(MODEL_PATH)
        
        # ìž…ë ¥ shape í™•ì¸
        if not hasattr(model, 'input_shape') or not model.input_shape:
            logging.warning("âš ï¸ ëª¨ë¸ì˜ ìž…ë ¥ shapeë¥¼ í™•ì¸í•  ìˆ˜ ì—†ì–´ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {
                "status": "skipped",
                "reason": "input_shape not available"
            }
        
        # ìž…ë ¥ shapeì—ì„œ None (ë°°ì¹˜ í¬ê¸°) ì œê±°
        input_shape = model.input_shape[1:] if model.input_shape[0] is None else model.input_shape
        
        logging.info(f"ìž…ë ¥ Shape (ë°°ì¹˜ ì œì™¸): {input_shape}")
        
        # ë”ë¯¸ ë°ì´í„° ìƒì„±
        batch_size = 1
        dummy_input = np.random.randn(batch_size, *input_shape).astype(np.float32)
        
        logging.info(f"ë”ë¯¸ ìž…ë ¥ ë°ì´í„° ìƒì„±: shape={dummy_input.shape}")
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        logging.info("ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
        prediction = model.predict(dummy_input, verbose=0)
        
        logging.info(f"âœ… ì˜ˆì¸¡ ì„±ê³µ!")
        logging.info(f"ì˜ˆì¸¡ ê²°ê³¼ Shape: {prediction.shape}")
        logging.info(f"ì˜ˆì¸¡ ê²°ê³¼ (ì²« ë²ˆì§¸ ìƒ˜í”Œ): {prediction[0]}")
        
        # ì˜ˆì¸¡ ê²°ê³¼ í†µê³„
        if prediction.size > 0:
            logging.info(f"ì˜ˆì¸¡ ê°’ ë²”ìœ„: [{prediction.min():.6f}, {prediction.max():.6f}]")
            logging.info(f"ì˜ˆì¸¡ ê°’ í‰ê· : {prediction.mean():.6f}")
            logging.info(f"ì˜ˆì¸¡ ê°’ í‘œì¤€íŽ¸ì°¨: {prediction.std():.6f}")
        
        return {
            "status": "success",
            "prediction_shape": list(prediction.shape),
            "prediction_sample": prediction[0].tolist() if prediction.size > 0 else None,
            "prediction_stats": {
                "min": float(prediction.min()) if prediction.size > 0 else None,
                "max": float(prediction.max()) if prediction.size > 0 else None,
                "mean": float(prediction.mean()) if prediction.size > 0 else None,
                "std": float(prediction.std()) if prediction.size > 0 else None,
            }
        }
        
    except Exception as e:
        error_msg = f"âŒ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
        logging.error(error_msg)
        logging.exception("ìƒì„¸ ì—ëŸ¬ ì •ë³´:")
        raise Exception(error_msg) from e


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DAG Definition
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

with DAG(
    dag_id="test_tensorflow_model_loading",
    default_args=DEFAULT_ARGS,
    description="TensorFlow CNN Anomaly Classifier ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸",
    schedule_interval=None,  # ìˆ˜ë™ ì‹¤í–‰
    catchup=False,
    tags=["ml", "tensorflow", "keras", "model", "test", "cnn", "anomaly"],
    max_active_runs=1,
) as dag:
    
    # 1. TensorFlow ìž„í¬íŠ¸ í…ŒìŠ¤íŠ¸
    test_import = PythonOperator(
        task_id="test_tensorflow_import",
        python_callable=test_tensorflow_import,
    )
    
    # 2. ëª¨ë¸ íŒŒì¼ í™•ì¸
    check_file = PythonOperator(
        task_id="check_model_file",
        python_callable=check_model_file,
    )
    
    # 3. ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
    load_model_task = PythonOperator(
        task_id="load_model",
        python_callable=load_model,
    )
    
    # 4. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    test_prediction = PythonOperator(
        task_id="test_model_prediction",
        python_callable=test_model_prediction,
    )
    
    # Task ì˜ì¡´ì„± ì„¤ì •
    test_import >> check_file >> load_model_task >> test_prediction

