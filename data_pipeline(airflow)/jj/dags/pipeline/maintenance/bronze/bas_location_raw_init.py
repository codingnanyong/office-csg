"""
BAS_LOCATION Initial Copy DAG
==============================
Oracle ICMMS.BAS_LOCATION í…Œì´ë¸”ì˜ ì „ì²´ ë°ì´í„°ë¥¼ PostgreSQLë¡œ ì´ˆê¸° ë³µì‚¬í•˜ëŠ” DAG
1íšŒ ì‹¤í–‰ìš© - Variable ì‚¬ìš© ì—†ìŒ

Source: Oracle ICMMS.BAS_LOCATION
Target: PostgreSQL bronze.bas_location_raw
Execution: Manual trigger only (@once)
"""

import logging
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from plugins.hooks.oracle_hook import OracleHelper
from plugins.hooks.postgres_hook import PostgresHelper

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Configuration Constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_ARGS = {
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'sla': timedelta(hours=1)
}

# Database Configuration
SCHEMA_NAME = "bronze"
TABLE_NAME = "bas_location_raw"

# Connection IDs
ORACLE_CONN_ID = "orc_jj_cmms"  # ICMMS ìŠ¤í‚¤ë§ˆ ì ‘ê·¼ ê°€ëŠ¥í•œ Oracle ì—°ê²°
POSTGRES_CONN_ID = "pg_jj_maintenance_dw"  # maintenance ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°

# Batch Configuration
BATCH_SIZE = 5000  # í•œ ë²ˆì— ì²˜ë¦¬í•  ë¡œìš° ìˆ˜

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ Data Extraction
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_extract_sql() -> str:
    """Build SQL query for full data extraction"""
    return '''
        SELECT
            COMPANY_CD, LOC_CD, LOC_NM, LOC_TYPE,
            HIGH1_CD, HIGH2_CD, HIGH3_CD,
            USE_YN, SORT_NO, LINE_CD, SHIFT_TYPE, COST_CD,
            REMARK, REG_USER, REG_IP, REG_DATE,
            UPD_USER, UPD_IP, UPD_DATE, WERKS
        FROM ICMMS.BAS_LOCATION
        ORDER BY COMPANY_CD, LOC_CD
    '''

def extract_data(oracle: OracleHelper) -> tuple:
    """Extract all data from Oracle database"""
    sql = build_extract_sql()
    logging.info("ğŸ” ì „ì²´ ë°ì´í„° ì¶”ì¶œ ì‹œì‘")
    logging.info(f"ì‹¤í–‰ ì¿¼ë¦¬: {sql}")
    
    data = oracle.execute_query(sql, task_id="extract_full_data", xcom_key=None)
    
    # Calculate row count from Oracle result
    if data and isinstance(data, list):
        row_count = len(data)
    elif data and hasattr(data, 'rowcount'):
        row_count = data.rowcount
    else:
        row_count = 0
    
    logging.info(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {row_count:,} rows")
    return data, row_count

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ Data Loading
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def prepare_insert_data(data: list, extract_time: datetime) -> list:
    """Prepare data for PostgreSQL insertion"""
    if not data:
        return []
    
    # Oracle ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ì§€ í™•ì¸í•˜ê³  ì²˜ë¦¬
    if isinstance(data[0], dict):
        # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° (OracleHelper ê²°ê³¼)
        return [
            (
                row['COMPANY_CD'], row['LOC_CD'], row['LOC_NM'], row['LOC_TYPE'],
                row['HIGH1_CD'], row['HIGH2_CD'], row['HIGH3_CD'],
                row['USE_YN'], row['SORT_NO'], row['LINE_CD'], row['SHIFT_TYPE'], row['COST_CD'],
                row['REMARK'], row['REG_USER'], row['REG_IP'], row['REG_DATE'],
                row['UPD_USER'], row['UPD_IP'], row['UPD_DATE'], row['WERKS'],
                extract_time, extract_time  # etl_extract_time, etl_ingest_time
            ) for row in data
        ]
    else:
        # íŠœí”Œ/ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš°
        return [
            (
                row[0], row[1], row[2], row[3],  # COMPANY_CD, LOC_CD, LOC_NM, LOC_TYPE
                row[4], row[5], row[6],  # HIGH1_CD, HIGH2_CD, HIGH3_CD
                row[7], row[8], row[9], row[10], row[11],  # USE_YN, SORT_NO, LINE_CD, SHIFT_TYPE, COST_CD
                row[12], row[13], row[14], row[15],  # REMARK, REG_USER, REG_IP, REG_DATE
                row[16], row[17], row[18], row[19],  # UPD_USER, UPD_IP, UPD_DATE, WERKS
                extract_time, extract_time
            ) for row in data
        ]

def get_column_names() -> list:
    """Get column names for PostgreSQL table"""
    return [
        "company_cd", "loc_cd", "loc_nm", "loc_type",
        "high1_cd", "high2_cd", "high3_cd",
        "use_yn", "sort_no", "line_cd", "shift_type", "cost_cd",
        "remark", "reg_user", "reg_ip", "reg_date",
        "upd_user", "upd_ip", "upd_date", "werks",
        "etl_extract_time", "etl_ingest_time"
    ]

def load_data(postgres: PostgresHelper, data: list) -> int:
    """Load data to PostgreSQL using insert_data method"""
    if not data:
        logging.warning("âš ï¸ ì ì¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return 0
    
    total_rows = len(data)
    logging.info(f"ğŸ“¦ ë°ì´í„° ì ì¬ ì‹œì‘: ì´ {total_rows:,} rows")
    
    try:
        columns = get_column_names()
        conflict_columns = ["company_cd", "loc_cd"]
        
        # PostgresHelperì˜ insert_data ë©”ì„œë“œ ì‚¬ìš©
        postgres.insert_data(
            schema_name=SCHEMA_NAME,
            table_name=TABLE_NAME,
            data=data,
            columns=columns,
            conflict_columns=conflict_columns,
            chunk_size=BATCH_SIZE
        )
        
        logging.info(f"ğŸ‰ ì „ì²´ ì ì¬ ì™„ë£Œ: {total_rows:,} rows")
        return total_rows
        
    except Exception as e:
        logging.error(f"âŒ ë°ì´í„° ì ì¬ ì‹¤íŒ¨: {str(e)}")
        raise

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4ï¸âƒ£ Main ETL Task
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def full_copy_etl(**kwargs):
    """
    Main ETL function for initial copy from Oracle to PostgreSQL
    1íšŒ ì‹¤í–‰ìš© - Variable ë¯¸ì‚¬ìš©
    """
    extract_time = datetime.now()
    logging.info(f"{'='*60}")
    logging.info(f"ğŸš€ BAS_LOCATION ì´ˆê¸° ë³µì‚¬ ì‹œì‘ (1íšŒ ì‹¤í–‰)")
    logging.info(f"{'='*60}")
    logging.info(f"ğŸ“… Extract Time: {extract_time}")
    
    try:
        # 1ï¸âƒ£ Extract from Oracle
        logging.info("\n" + "â”€"*60)
        logging.info("1ï¸âƒ£ Oracle ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        logging.info("â”€"*60)
        
        oracle = OracleHelper(conn_id=ORACLE_CONN_ID)
        
        # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
        if not oracle.check_table("ICMMS", "BAS_LOCATION"):
            raise Exception("âŒ Oracle í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ICMMS.BAS_LOCATION")
        
        data, extract_count = extract_data(oracle)
        
        if not data or extract_count == 0:
            logging.warning("âš ï¸ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—… ì¢…ë£Œ.")
            return {
                "status": "success",
                "message": "No data to process",
                "extracted": 0,
                "loaded": 0
            }
        
        # 2ï¸âƒ£ Transform (Prepare data)
        logging.info("\n" + "â”€"*60)
        logging.info("2ï¸âƒ£ ë°ì´í„° ë³€í™˜ ì¤‘...")
        logging.info("â”€"*60)
        
        prepared_data = prepare_insert_data(data, extract_time)
        logging.info(f"âœ… ë³€í™˜ ì™„ë£Œ: {len(prepared_data):,} rows")
        
        # 3ï¸âƒ£ Load to PostgreSQL
        logging.info("\n" + "â”€"*60)
        logging.info("3ï¸âƒ£ PostgreSQL ì ì¬ ì¤‘...")
        logging.info("â”€"*60)
        
        postgres = PostgresHelper(conn_id=POSTGRES_CONN_ID)
        
        # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
        if not postgres.check_table(SCHEMA_NAME, TABLE_NAME):
            raise Exception(f"âŒ PostgreSQL í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {SCHEMA_NAME}.{TABLE_NAME}")
        
        loaded_count = load_data(postgres, prepared_data)
        
        # 4ï¸âƒ£ Summary
        logging.info("\n" + "="*60)
        logging.info("âœ… ETL ì™„ë£Œ")
        logging.info("="*60)
        logging.info(f"ğŸ“Š ì¶”ì¶œ: {extract_count:,} rows")
        logging.info(f"ğŸ“Š ì ì¬: {loaded_count:,} rows")
        logging.info(f"â±ï¸  ì†Œìš” ì‹œê°„: {datetime.now() - extract_time}")
        logging.info("="*60)
        
        return {
            "status": "success",
            "extract_time": extract_time.isoformat(),
            "extracted": extract_count,
            "loaded": loaded_count,
            "duration": str(datetime.now() - extract_time)
        }
        
    except Exception as e:
        logging.error(f"\n{'='*60}")
        logging.error(f"âŒ ETL ì‹¤íŒ¨: {str(e)}")
        logging.error(f"{'='*60}")
        raise

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5ï¸âƒ£ DAG Definition
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with DAG(
    dag_id='bas_location_raw_init',
    default_args=DEFAULT_ARGS,
    description='ICMMS.BAS_LOCATION ì „ì²´ ë°ì´í„° ì´ˆê¸° ë³µì‚¬ (Oracle â†’ PostgreSQL) - 1íšŒ ì‹¤í–‰',
    schedule_interval=None,  # Manual trigger only
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['JJ', 'maintenance', 'bronze layer', 'raw', 'init', 'master', 'location'],
    max_active_runs=1,
) as dag:
    
    init_copy_task = PythonOperator(
        task_id='init_copy_bas_location',
        python_callable=full_copy_etl,
        provide_context=True,
    )
    
    init_copy_task

