"""BAS Defective Raw Incremental DAG (Oracle â†’ Bronze)"""
import logging
from datetime import datetime, timedelta, timezone
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from dags.pipeline.maintenance.bronze.common.bas_deffective_raw_common import (
    process_single_date,
    update_variable,
    INDO_TZ,
    ORACLE_CONN_ID,
    POSTGRES_CONN_ID,
    SCHEMA_NAME,
    TABLE_NAME
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1ï¸âƒ£ Configuration Constants
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DEFAULT_ARGS = {
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'sla': timedelta(hours=2)
}

INCREMENT_KEY = "last_extract_time_bas_deffective_raw"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2ï¸âƒ£ Main ETL Logic
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def daily_incremental_collection_task(**kwargs) -> dict:
    """ë§¤ì¼ ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘í•˜ëŠ” íƒœìŠ¤í¬"""
    # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ ë‚  ë°ì´í„° ìˆ˜ì§‘
    last_extract_time_str = Variable.get(INCREMENT_KEY, default_var=None)
    
    if last_extract_time_str:
        from dags.pipeline.maintenance.bronze.common.bas_deffective_raw_common import parse_datetime
        
        # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì„ íŒŒì‹±
        last_extract_time = parse_datetime(last_extract_time_str)
        
        # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì˜ ë‹¤ìŒ ë‚  00:00:00ë¶€í„° 23:59:59ê¹Œì§€
        start_date = last_extract_time.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(days=1)
        target_date_str = start_date.strftime('%Y-%m-%d')
        
        logging.info(f"ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„: {last_extract_time_str}")
        logging.info(f"ë‹¤ìŒ ë‚  ë°ì´í„° ìˆ˜ì§‘: {target_date_str}")
    else:
        # Variableì´ ì—†ìœ¼ë©´ ì–´ì œ ë°ì´í„° ìˆ˜ì§‘
        yesterday = datetime.now(INDO_TZ) - timedelta(days=1)
        target_date_str = yesterday.strftime('%Y-%m-%d')
        logging.info(f"Variableì´ ì—†ì–´ì„œ ì–´ì œ ë°ì´í„° ìˆ˜ì§‘: {target_date_str}")
    
    logging.info(f"ğŸ“Š ì²˜ë¦¬ ë‚ ì§œ: {target_date_str}")
    
    # ë‹¨ì¼ ë‚ ì§œ ì²˜ë¦¬
    result = process_single_date(
        target_date_str,
        ORACLE_CONN_ID,
        POSTGRES_CONN_ID,
        SCHEMA_NAME,
        TABLE_NAME
    )
    
    # Variable ì—…ë°ì´íŠ¸ (ì„±ê³µ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ì‹œê°„ ì—…ë°ì´íŠ¸)
    if result.get('status') == 'success':
        end_str = result.get('end_time')
        update_variable(INCREMENT_KEY, end_str)
    
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3ï¸âƒ£ DAG Definition
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

with DAG(
    dag_id="bas_deffective_raw_incremental",
    default_args=DEFAULT_ARGS,
    schedule_interval="@daily",
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=["JJ", "raw", "bronze layer", "incremental", "maintenance", "daily"],
) as dag:
    
    daily_collection = PythonOperator(
        task_id="daily_incremental_collection",
        python_callable=daily_incremental_collection_task,
    )
    
    daily_collection
