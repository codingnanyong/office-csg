import logging
from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta, timezone
from plugins.hooks.oracle_hook import OracleHelper
from plugins.hooks.postgres_hook import PostgresHelper
from dags.pipeline.production.bronze.common.sss_php_so_common import (
    parse_datetime,
    extract_data,
    load_data,
    update_variable,
    INDO_TZ,
    ORACLE_CONN_ID,
    POSTGRES_CONN_ID
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Configuration Constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_ARGS = {
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'sla': timedelta(hours=2)
}

# Database Configuration
INCREMENT_KEY = "last_extract_time_sss_php_so"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ Daily Incremental Collection
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def daily_incremental_collection_task(**kwargs) -> dict:
    """UTC 00:00:00 ì‹¤í–‰ ì‹œ ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì ë¶€í„° ì˜¤ëŠ˜ 06:30:00ê¹Œì§€ ìˆ˜ì§‘"""
    oracle = OracleHelper(conn_id=ORACLE_CONN_ID)
    pg = PostgresHelper(conn_id=POSTGRES_CONN_ID)
    
    # Airflow execution date (UTC ê¸°ì¤€)
    # data_interval_endê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ execution_date ì‚¬ìš©
    execution_date = kwargs.get('data_interval_end') or kwargs.get('execution_date')
    
    # ëª©í‘œ ì¢…ë£Œ ì‹œì  ê³„ì‚° (ì˜¤ëŠ˜ 06:30:00)
    if execution_date:
        # UTC ì‹œê°„ì„ ì¸ë„ë„¤ì‹œì•„ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
        if execution_date.tzinfo is None:
            # UTCë¡œ ê°€ì •
            execution_date_utc = execution_date.replace(tzinfo=timezone.utc)
        else:
            execution_date_utc = execution_date.astimezone(timezone.utc)
        
        # UTCë¥¼ ì¸ë„ë„¤ì‹œì•„ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (UTC+7)
        execution_date_indo = execution_date_utc.astimezone(INDO_TZ)
        logging.info(f"ğŸ“… ì‹¤í–‰ ì‹œê°„ (UTC): {execution_date_utc.strftime('%Y-%m-%d %H:%M:%S %Z')}")
        logging.info(f"ğŸ“… ì‹¤í–‰ ì‹œê°„ (ì¸ë„ë„¤ì‹œì•„): {execution_date_indo.strftime('%Y-%m-%d %H:%M:%S %Z')}")
        
        # ëª©í‘œ ì¢…ë£Œ ì‹œì : ì˜¤ëŠ˜ 06:30:00
        target_end_date = execution_date_indo.replace(hour=6, minute=30, second=0, microsecond=0)
    else:
        # execution_dateê°€ ì—†ìœ¼ë©´ (ìˆ˜ë™ ì‹¤í–‰ ë“±) í˜„ì¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        now_indo = datetime.now(INDO_TZ)
        target_end_date = now_indo.replace(hour=6, minute=30, second=0, microsecond=0)
        logging.info(f"âš ï¸ execution_dateê°€ ì—†ì–´ì„œ í˜„ì¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°")
    
    # ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì  í™•ì¸
    last_extract_time_str = Variable.get(INCREMENT_KEY, default_var=None)
    
    if last_extract_time_str:
        # ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì ì´ ìˆìœ¼ë©´ ê·¸ ì‹œì  + 1ì´ˆë¶€í„° ì‹œì‘
        last_extract_time = parse_datetime(last_extract_time_str)
        if last_extract_time.tzinfo is None:
            last_extract_time = last_extract_time.replace(tzinfo=INDO_TZ)
        
        logging.info(f"ğŸ“Œ ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì : {last_extract_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì ì´ ì´ë¯¸ ëª©í‘œ ì¢…ë£Œ ì‹œì  ì´í›„ë©´ ìŠ¤í‚µ
        if last_extract_time >= target_end_date:
            logging.info(f"â­ï¸ ì´ë¯¸ ìˆ˜ì§‘ ì™„ë£Œ: ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì ({last_extract_time.strftime('%Y-%m-%d %H:%M:%S')}) >= ëª©í‘œ ì¢…ë£Œ ì‹œì ({target_end_date.strftime('%Y-%m-%d %H:%M:%S')})")
            return {
                "status": "already_collected",
                "last_extract_time": last_extract_time.strftime("%Y-%m-%d %H:%M:%S"),
                "target_end_time": target_end_date.strftime("%Y-%m-%d %H:%M:%S"),
                "rows_processed": 0,
                "message": "ì´ë¯¸ ìˆ˜ì§‘ ì™„ë£Œëœ êµ¬ê°„"
            }
        
        # ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì  + 1ì´ˆë¶€í„° ì‹œì‘
        start_date = last_extract_time + timedelta(seconds=1)
        end_date = target_end_date
        logging.info(f"ğŸ“… ìˆ˜ì§‘ êµ¬ê°„: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')} (ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì ë¶€í„°)")
    else:
        # ë§ˆì§€ë§‰ ìˆ˜ì§‘ ì‹œì ì´ ì—†ìœ¼ë©´ ì „ë‚  06:30:00ë¶€í„° ì‹œì‘
        yesterday_indo = target_end_date - timedelta(days=1)
        start_date = yesterday_indo.replace(hour=6, minute=30, second=0, microsecond=0)
        end_date = target_end_date
        logging.info(f"ğŸ“… ìˆ˜ì§‘ êµ¬ê°„: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')} (Variable ì—†ìŒ, ì „ë‚  06:30ë¶€í„°)")
    
    start_str = start_date.strftime("%Y-%m-%d %H:%M:%S")
    end_str = end_date.strftime("%Y-%m-%d %H:%M:%S")
    
    logging.info(f"ğŸ“… ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_str} ~ {end_str}")
    logging.info(f"ğŸ“Š ì²˜ë¦¬ ë‚ ì§œ: {start_date.strftime('%Y-%m-%d')}")
    
    # ë°ì´í„° ì¶”ì¶œ ë° ì ì¬
    data, row_count = extract_data(oracle, start_str, end_str)
    
    if row_count > 0:
        extract_time = datetime.utcnow()
        load_data(pg, data, extract_time)
        logging.info(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {row_count} rows")
        
        # Variable ì—…ë°ì´íŠ¸ (ì¢…ë£Œ ì‹œê°„ì„ 06:30:00ìœ¼ë¡œ ì„¤ì •)
        update_variable(INCREMENT_KEY, end_str)
        
        return {
            "status": "daily_incremental_completed",
            "date": start_date.strftime("%Y-%m-%d"),
            "rows_processed": row_count,
            "start_time": start_str,
            "end_time": end_str,
            "extract_time": extract_time.isoformat()
        }
    else:
        logging.info(f"âš ï¸ ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {start_str} ~ {end_str}")
        
        # Variable ì—…ë°ì´íŠ¸ (ë°ì´í„°ê°€ ì—†ì–´ë„ ì‹œê°„ì€ ì—…ë°ì´íŠ¸, ì¢…ë£Œ ì‹œê°„ì„ 06:30:00ìœ¼ë¡œ ì„¤ì •)
        update_variable(INCREMENT_KEY, end_str)
        
        return {
            "status": "daily_incremental_completed_no_data",
            "date": start_date.strftime("%Y-%m-%d"),
            "rows_processed": 0,
            "start_time": start_str,
            "end_time": end_str,
            "message": "ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŒ"
        }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ DAG Definition
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with DAG(
    dag_id="sss_php_so_incremental",
    default_args=DEFAULT_ARGS,
    schedule_interval=None,  # ë§¤ì¼ ì‹¤í–‰
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=["JJ","raw", "PHP","Plan", "bronze layer", "incremental", "production"]
) as dag:
    
    daily_collection = PythonOperator(
        task_id="daily_incremental_collection",
        python_callable=daily_incremental_collection_task,
        provide_context=True,
    )
    
    daily_collection

