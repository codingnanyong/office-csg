"""
MSPD PCARD Result Raw Incremental DAG
======================================
Oracle LMES.MSPD_PCARD_RESULT í…Œì´ë¸”ì˜ ì¦ë¶„ ë°ì´í„°ë¥¼ PostgreSQLë¡œ ìˆ˜ì§‘í•˜ëŠ” DAG

Source: Oracle LMES.MSPD_PCARD_RESULT
Target: PostgreSQL bronze.mspd_pcard_result_raw
Execution: Daily incremental collection
"""

import logging
from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from plugins.hooks.oracle_hook import OracleHelper
from plugins.hooks.postgres_hook import PostgresHelper
from dags.pipeline.production.bronze.common.mspd_pcard_result_raw_common import (
    parse_datetime,
    extract_data,
    load_data,
    update_variable,
    _normalize_to_0630,
    INDO_TZ,
    ORACLE_CONN_ID,
    POSTGRES_CONN_ID
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Configuration Constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_ARGS = {
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'sla': timedelta(hours=2)
}

# Database Configuration
INCREMENT_KEY = "last_extract_time_mspd_pcard_result_raw"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ Daily Incremental Collection
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def daily_incremental_collection_task(**kwargs) -> dict:
    """ë§¤ì¼ ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘í•˜ëŠ” íƒœìŠ¤í¬ (06:30 ê¸°ì¤€)"""
    oracle = OracleHelper(conn_id=ORACLE_CONN_ID)
    pg = PostgresHelper(conn_id=POSTGRES_CONN_ID)
    
    # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ ë‚  ë°ì´í„° ìˆ˜ì§‘ (06:30 ê¸°ì¤€)
    last_extract_time_str = Variable.get(INCREMENT_KEY, default_var=None)
    
    if last_extract_time_str:
        # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì„ íŒŒì‹±
        last_extract_time = parse_datetime(last_extract_time_str)
        
        # ë§ˆì§€ë§‰ ì²˜ë¦¬ ì‹œê°„ì„ 06:30ìœ¼ë¡œ ì •ê·œí™”í•˜ê³ , ë‹¤ìŒë‚  06:30ê¹Œì§€ ì²˜ë¦¬
        start_date = _normalize_to_0630(last_extract_time)
        end_date = _normalize_to_0630(last_extract_time + timedelta(days=1))
        
        logging.info(f"ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„: {last_extract_time_str}")
        logging.info(f"ë‹¤ìŒ ë‚  ë°ì´í„° ìˆ˜ì§‘ (06:30 ê¸°ì¤€): {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        # Variableì´ ì—†ìœ¼ë©´ ì–´ì œ 06:30ë¶€í„° ì˜¤ëŠ˜ 06:30ê¹Œì§€ ë°ì´í„° ìˆ˜ì§‘
        yesterday = datetime.now(INDO_TZ) - timedelta(days=1)
        start_date = _normalize_to_0630(yesterday)
        end_date = _normalize_to_0630(yesterday + timedelta(days=1))
        logging.info(f"Variableì´ ì—†ì–´ì„œ ì–´ì œ 06:30ë¶€í„° ì˜¤ëŠ˜ 06:30ê¹Œì§€ ë°ì´í„° ìˆ˜ì§‘: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')}")
    
    start_str = start_date.strftime("%Y-%m-%d %H:%M:%S")
    end_str = end_date.strftime("%Y-%m-%d %H:%M:%S")
    
    logging.info(f"ğŸ“… ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_str} ~ {end_str}")
    logging.info(f"ğŸ“Š ì²˜ë¦¬ ë‚ ì§œ: {start_date.strftime('%Y-%m-%d')}")
    
    # ë°ì´í„° ì¶”ì¶œ ë° ì ì¬
    data, row_count = extract_data(oracle, start_str, end_str)
    
    if row_count > 0:
        extract_time = datetime.utcnow()
        load_data(pg, data, extract_time)
        logging.info(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {row_count} rows")
        
        # Variable ì—…ë°ì´íŠ¸
        update_variable(INCREMENT_KEY, end_str)
        
        return {
            "status": "daily_incremental_completed",
            "date": start_date.strftime("%Y-%m-%d"),
            "rows_processed": row_count,
            "start_time": start_str,
            "end_time": end_str,
            "extract_time": extract_time.isoformat()
        }
    else:
        logging.info(f"âš ï¸ ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {start_str} ~ {end_str}")
        
        # Variable ì—…ë°ì´íŠ¸ (ë°ì´í„°ê°€ ì—†ì–´ë„ ì‹œê°„ì€ ì—…ë°ì´íŠ¸)
        update_variable(INCREMENT_KEY, end_str)
        
        return {
            "status": "daily_incremental_completed_no_data",
            "date": start_date.strftime("%Y-%m-%d"),
            "rows_processed": 0,
            "start_time": start_str,
            "end_time": end_str,
            "message": "ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŒ"
        }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ DAG Definition
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with DAG(
    dag_id="mspd_pcard_result_raw_incremental",
    default_args=DEFAULT_ARGS,
    schedule_interval="@daily",  # TODO: ìŠ¤ì¼€ì¤„ ì„¤ì • í•„ìš” (ì˜ˆ: "0 1 * * *" - ë§¤ì¼ 01:00)
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=["JJ", "raw", "bronze layer", "incremental", "production", "daily"]
) as dag:
    
    daily_collection = PythonOperator(
        task_id="daily_incremental_collection",
        python_callable=daily_incremental_collection_task,
        provide_context=True,
    )
    
    daily_collection

