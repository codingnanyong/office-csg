import logging
from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from plugins.hooks.oracle_hook import OracleHelper
from plugins.hooks.postgres_hook import PostgresHelper
from dags.pipeline.production.bronze.common.smp_ss_ipi_rst_raw_common import (
    parse_datetime,
    extract_data,
    load_data,
    update_variable,
    INDO_TZ,
    ORACLE_CONN_ID,
    POSTGRES_CONN_ID
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Configuration Constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_ARGS = {
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'sla': timedelta(hours=2)
}

# Database Configuration
INCREMENT_KEY = "last_extract_time_smp_ss_ipi_rst_raw"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ Daily Incremental Collection
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def daily_incremental_collection_task(**kwargs) -> dict:
    """06:30 ~ ë‹¤ìŒë‚  06:30 ìŠ¤ì¼€ì¤„ë¡œ ë°ì´í„° ìˆ˜ì§‘í•˜ëŠ” íƒœìŠ¤í¬"""
    oracle = OracleHelper(conn_id=ORACLE_CONN_ID)
    pg = PostgresHelper(conn_id=POSTGRES_CONN_ID)
    
    # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ ê¸°ê°„ ë°ì´í„° ìˆ˜ì§‘
    last_extract_time_str = Variable.get(INCREMENT_KEY, default_var=None)
    
    if last_extract_time_str:
        # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì„ íŒŒì‹±
        last_extract_time = parse_datetime(last_extract_time_str)
        
        # ê¸°ì¡´ ìŠ¤ì¼€ì¤„(23:59:59ë¡œ ëë‚˜ëŠ” ê²½ìš°)ì—ì„œ ìƒˆ ìŠ¤ì¼€ì¤„(06:30)ë¡œ ì „í™˜í•˜ëŠ” ê²½ìš°
        if last_extract_time.hour == 23 and last_extract_time.minute == 59 and last_extract_time.second == 59:
            # ë‹¤ìŒë‚  00:00:00ë¶€í„° ê·¸ ë‹¤ìŒë‚  06:30:00ê¹Œì§€ (ì²« ë²ˆì§¸ ì „í™˜)
            start_date = last_extract_time.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(days=1)
            end_date = start_date.replace(hour=6, minute=30, second=0, microsecond=0) + timedelta(days=1)
            logging.info(f"ğŸ”„ ìŠ¤ì¼€ì¤„ ì „í™˜: ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ {last_extract_time_str} â†’ ìƒˆ ìŠ¤ì¼€ì¤„ ì ìš©")
            logging.info(f"ğŸ“… ì²« ì „í™˜ ìˆ˜ì§‘ ê¸°ê°„: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')}")
        else:
            # ì •ìƒ ìŠ¤ì¼€ì¤„: ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì˜ ë‹¤ìŒ 06:30:01ë¶€í„° ë‹¤ìŒë‚  06:30:00ê¹Œì§€
            # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì´ 06:30:00ì´ë©´, ê·¸ ë‚ ì§œì˜ 06:30:01ë¶€í„° ì‹œì‘
            if last_extract_time.hour == 6 and last_extract_time.minute == 30 and last_extract_time.second == 0:
                # ê°™ì€ ë‚ ì§œì˜ 06:30:01ë¶€í„° ë‹¤ìŒë‚  06:30:00ê¹Œì§€
                start_date = last_extract_time.replace(second=1, microsecond=0)
                end_date = start_date.replace(hour=6, minute=30, second=0, microsecond=0) + timedelta(days=1)
            else:
                # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ 06:30:01 ì„¤ì •
                base_date = last_extract_time.replace(hour=6, minute=30, second=1, microsecond=0)
                # ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„ì´ ì´ë¯¸ 06:30:01 ì´í›„ë¼ë©´ ë‹¤ìŒë‚ ë¡œ
                if (last_extract_time.hour > 6) or (last_extract_time.hour == 6 and last_extract_time.minute > 30) or (last_extract_time.hour == 6 and last_extract_time.minute == 30 and last_extract_time.second >= 1):
                    start_date = base_date + timedelta(days=1)
                else:
                    start_date = base_date
                
                # ì¢…ë£Œ ì‹œê°„: ì‹œì‘ ë‚ ì§œì˜ ë‹¤ìŒë‚  06:30:00
                end_date = start_date.replace(hour=6, minute=30, second=0, microsecond=0) + timedelta(days=1)
            
            logging.info(f"ë§ˆì§€ë§‰ ì¶”ì¶œ ì‹œê°„: {last_extract_time_str}")
            logging.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        # Variableì´ ì—†ìœ¼ë©´ ì–´ì œ 06:30:00ë¶€í„° ì˜¤ëŠ˜ 06:30:00ê¹Œì§€ ìˆ˜ì§‘
        yesterday = datetime.now(INDO_TZ) - timedelta(days=1)
        start_date = yesterday.replace(hour=6, minute=30, second=0, microsecond=0)
        end_date = datetime.now(INDO_TZ).replace(hour=6, minute=30, second=0, microsecond=0)
        logging.info(f"Variableì´ ì—†ì–´ì„œ ì–´ì œ 06:30ë¶€í„° ì˜¤ëŠ˜ 06:30ê¹Œì§€ ìˆ˜ì§‘: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')}")
    
    start_str = start_date.strftime("%Y-%m-%d %H:%M:%S")
    end_str = end_date.strftime("%Y-%m-%d %H:%M:%S")
    
    logging.info(f"ğŸ“… ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_str} ~ {end_str}")
    logging.info(f"ğŸ“Š ì²˜ë¦¬ ë‚ ì§œ: {start_date.strftime('%Y-%m-%d')}")
    
    # ë°ì´í„° ì¶”ì¶œ ë° ì ì¬
    data, row_count = extract_data(oracle, start_str, end_str)
    
    if row_count > 0:
        extract_time = datetime.utcnow()
        load_data(pg, data, extract_time)
        logging.info(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {row_count} rows")
        
        # Variable ì—…ë°ì´íŠ¸ (ì¢…ë£Œ ì‹œê°„ì„ 06:30:00ìœ¼ë¡œ ì„¤ì •)
        update_variable(INCREMENT_KEY, end_str)
        
        return {
            "status": "daily_incremental_completed",
            "date": start_date.strftime("%Y-%m-%d"),
            "rows_processed": row_count,
            "start_time": start_str,
            "end_time": end_str,
            "extract_time": extract_time.isoformat()
        }
    else:
        logging.info(f"âš ï¸ ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {start_str} ~ {end_str}")
        
        # Variable ì—…ë°ì´íŠ¸ (ë°ì´í„°ê°€ ì—†ì–´ë„ ì‹œê°„ì€ ì—…ë°ì´íŠ¸, ì¢…ë£Œ ì‹œê°„ì„ 06:30:00ìœ¼ë¡œ ì„¤ì •)
        update_variable(INCREMENT_KEY, end_str)
        
        return {
            "status": "daily_incremental_completed_no_data",
            "date": start_date.strftime("%Y-%m-%d"),
            "rows_processed": 0,
            "start_time": start_str,
            "end_time": end_str,
            "message": "ìˆ˜ì§‘í•  ë°ì´í„°ê°€ ì—†ìŒ"
        }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ DAG Definition
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with DAG(
    dag_id="smp_ss_ipi_rst_raw_incremental",
    default_args=DEFAULT_ARGS,
    schedule_interval=None,  # ë§¤ì¼ ì‹¤í–‰
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=["JJ","raw", "IP","IPI", "bronze layer", "incremental", "production"]
) as dag:
    
    daily_collection = PythonOperator(
        task_id="daily_incremental_collection",
        python_callable=daily_incremental_collection_task,
        provide_context=True,
    )
    
    daily_collection
