"""
IPI Time Correction Backfill DAG (Bronze â†’ Silver)
====================================================
ê³¼ê±° ë°ì´í„°ë¥¼ ìŒ“ëŠ” Backfill DAG (-2ì¼ ì „ê¹Œì§€)

Source Tables:
- bronze.ipi_mc_output_v2_raw (pg_jj_production_dw)
- bronze.mspq_in_osnd_bt_ipi_raw (pg_jj_quality_dw)

Target: silver.ipi_defective_time_corrected (pg_jj_quality_dw)
Execution: Manual trigger only
"""

import logging
import pandas as pd
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from plugins.hooks.postgres_hook import PostgresHelper
from dags.pipeline.quality.silver.common.ipi_defective_time_correction_common import (
    extract_mc_data,
    extract_ipi_data,
    normalize_strings,
    parse_datetimes,
    perform_time_matching,
    filter_by_delta_threshold,
    load_to_silver,
    update_variable,
    PRODUCTION_POSTGRES_CONN_ID,
    QUALITY_POSTGRES_CONN_ID,
    DELTA_SEC_THRESHOLD,
    INITIAL_START_DATE,
    DAYS_OFFSET_FOR_INCREMENTAL
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Configuration Constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_ARGS = {
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'sla': timedelta(hours=2),
}

# Backfill Configuration
INCREMENT_KEY = "ipi_defective_time_corrected_last_date"  # incrementalê³¼ ê³µìš©


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ Main Backfill Logic
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_daily_batch(
    pg_prod: PostgresHelper,
    pg_quality: PostgresHelper,
    start_date: datetime,
    loop_count: int,
    expected_days: int
) -> dict:
    """Process a single daily batch"""
    logging.info(f"ğŸ”„ ë£¨í”„ {loop_count}/{expected_days} ì‹œì‘")
    
    start_time = start_date.strftime("%Y-%m-%d")
    end_time = start_date.strftime("%Y-%m-%d")
    
    logging.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {start_time}")
    
    try:
        # ë°ì´í„° ì¶”ì¶œ
        mc_df = extract_mc_data(pg_prod, start_time, end_time)
        ipi_df = extract_ipi_data(pg_quality, start_time, end_time)
        
        if len(mc_df) == 0:
            logging.warning(f"âš ï¸ MC ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {start_time}")
            update_variable(INCREMENT_KEY, start_time)
            return {
                "loop": loop_count,
                "date": start_time,
                "status": "no_mc_data"
            }
        
        if len(ipi_df) == 0:
            logging.warning(f"âš ï¸ IPI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {start_time}")
            update_variable(INCREMENT_KEY, start_time)
            return {
                "loop": loop_count,
                "date": start_time,
                "status": "no_ipi_data"
            }
        
        # ë¬¸ìì—´ ì •ê·œí™”
        mc_df, ipi_df = normalize_strings(mc_df, ipi_df)
        
        # ì‹œê°„ íŒŒì‹±
        mc_df, ipi_df = parse_datetimes(mc_df, ipi_df)
        
        # ì‹œê°„ ë§¤ì¹­ ë£¨í”„ ìˆ˜í–‰
        ipi_df = perform_time_matching(mc_df, ipi_df)
        
        # Delta ì´ˆê³¼ ë²”ìœ„ í•„í„°ë§
        df_normal, df_exceed = filter_by_delta_threshold(ipi_df, DELTA_SEC_THRESHOLD)
        
        # Silver í…Œì´ë¸” ì ì¬
        if len(df_normal) > 0:
            load_to_silver(pg_quality, df_normal)
            logging.info(f"âœ… ë°°ì¹˜ ì™„ë£Œ: {start_time} ({len(df_normal):,} rows)")
        else:
            logging.info(f"ë°°ì¹˜ì— ë°ì´í„° ì—†ìŒ: {start_time}")
        
        # Variable ì—…ë°ì´íŠ¸
        update_variable(INCREMENT_KEY, start_time)
        
        return {
            "loop": loop_count,
            "date": start_time,
            "original_rows": len(ipi_df),
            "final_rows": len(df_normal),
            "exceed_rows": len(df_exceed),
            "status": "success"
        }
        
    except Exception as e:
        logging.error(f"âŒ ë°°ì¹˜ ì‹¤íŒ¨: {start_time} - {str(e)}")
        update_variable(INCREMENT_KEY, start_time)  # ì‹¤íŒ¨í•´ë„ ë‚ ì§œëŠ” ì—…ë°ì´íŠ¸
        return {
            "loop": loop_count,
            "date": start_time,
            "status": "failed",
            "error": str(e)
        }


def backfill_daily_batch_task(**kwargs) -> dict:
    """Main backfill task for daily batch processing"""
    pg_prod = PostgresHelper(conn_id=PRODUCTION_POSTGRES_CONN_ID)
    pg_quality = PostgresHelper(conn_id=QUALITY_POSTGRES_CONN_ID)
    
    # Get start date from variable or use initial date
    last_date_str = Variable.get(INCREMENT_KEY, default_var=None)
    if not last_date_str:
        start_date = INITIAL_START_DATE
        logging.info(f"ì´ˆê¸° ì‹œì‘ ë‚ ì§œ ì‚¬ìš©: {start_date}")
    else:
        start_date = datetime.strptime(last_date_str, '%Y-%m-%d')
        logging.info(f"ì´ì „ ì§„í–‰ ì§€ì  ì‚¬ìš©: {start_date}")
    
    # Calculate end date (today - 2 days)
    end_date = (datetime.now() - timedelta(days=DAYS_OFFSET_FOR_INCREMENTAL)).replace(
        hour=0, minute=0, second=0, microsecond=0
    )
    
    # Calculate expected days
    expected_days = (end_date - start_date).days
    
    # Log backfill information
    logging.info(f"Backfill ì‹œì‘: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    logging.info(f"ë°°ì¹˜ í¬ê¸°: ì¼ë³„ (í•˜ë£¨ì”© ì²˜ë¦¬)")
    logging.info(f"ì˜ˆìƒ ë£¨í”„ íšŸìˆ˜: {expected_days}íšŒ (ì¼ë³„)")
    logging.info(f"âš ï¸ í˜„ì¬ ì‹œê°„ì—ì„œ {DAYS_OFFSET_FOR_INCREMENTAL}ì¼ ì „ìœ¼ë¡œ ì„¤ì • (incremental DAG ì‹œì‘ì )")
    logging.info(f"â±ï¸  Delta Threshold: {DELTA_SEC_THRESHOLD}ì´ˆ")
    
    # Process daily batches
    results = []
    total_original_rows = 0
    total_final_rows = 0
    total_exceed_rows = 0
    loop_count = 0
    current_date = start_date
    
    while current_date < end_date:
        loop_count += 1
        
        # Process batch
        batch_result = process_daily_batch(
            pg_prod, pg_quality, current_date, loop_count, expected_days
        )
        
        results.append(batch_result)
        
        if batch_result.get("status") == "success":
            total_original_rows += batch_result.get("original_rows", 0)
            total_final_rows += batch_result.get("final_rows", 0)
            total_exceed_rows += batch_result.get("exceed_rows", 0)
        
        # Move to next day
        current_date += timedelta(days=1)
    
    # Log completion
    logging.info(f"ğŸ‰ Backfill ì™„ë£Œ! ì´ {loop_count}íšŒ ë£¨í”„, {total_final_rows:,}ê°œ rows ìˆ˜ì§‘")
    if results:
        logging.info(f"ì²˜ë¦¬ ê¸°ê°„: {results[0]['date']} ~ {results[-1]['date']}")
        logging.info(f"ğŸ“Š ì´ ì›ë³¸ ë°ì´í„°: {total_original_rows:,} rows")
        logging.info(f"ğŸ“Š ì´ ìµœì¢… ë°ì´í„°: {total_final_rows:,} rows")
        logging.info(f"ğŸ“Š ì´ ì´ˆê³¼ ë²”ìœ„ ë°ì´í„°: {total_exceed_rows:,} rows")
    
    return {
        "status": "backfill_completed",
        "total_loops": loop_count,
        "total_days": len(results),
        "total_original_rows": total_original_rows,
        "total_final_rows": total_final_rows,
        "total_exceed_rows": total_exceed_rows,
        "results": results
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ DAG Definition
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with DAG(
    dag_id='ipi_defective_time_correction_backfill',
    default_args=DEFAULT_ARGS,
    description='IPI Defective Time Correction Backfill - ê³¼ê±° ë°ì´í„° ì ì¬ (-2ì¼ ì „ê¹Œì§€)',
    schedule_interval=None,  # Manual trigger only
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['JJ', 'quality', 'IP', 'Silver Layer', 'backfill', 'IPI'],
    max_active_runs=1,
) as dag:
    
    backfill_daily_batch = PythonOperator(
        task_id="backfill_daily_batch_task",
        python_callable=backfill_daily_batch_task,
        provide_context=True,
    )
    
    backfill_daily_batch

