"""
IPI Time Correction Incremental DAG (Bronze â†’ Silver)
=======================================================
ì „ì¼ ë°ì´í„°ë¥¼ ìŒ“ëŠ” Incremental DAG

Source Tables:
- bronze.ipi_mc_output_v2_raw (pg_jj_production_dw)
- bronze.mspq_in_osnd_bt_ipi_raw (pg_jj_quality_dw)

Target: silver.ipi_defective_time_corrected (pg_jj_quality_dw)
Execution: Daily schedule (@daily)
"""

import logging
import pandas as pd
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from plugins.hooks.postgres_hook import PostgresHelper
from dags.pipeline.quality.silver.common.ipi_defective_time_correction_common import (
    extract_mc_data,
    extract_ipi_data,
    normalize_strings,
    parse_datetimes,
    perform_time_matching,
    filter_by_delta_threshold,
    load_to_silver,
    update_variable,
    PRODUCTION_POSTGRES_CONN_ID,
    QUALITY_POSTGRES_CONN_ID,
    DELTA_SEC_THRESHOLD
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Configuration Constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_ARGS = {
    'owner': 'airflow',
    'depends_on_past': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'sla': timedelta(hours=2),
}

# Incremental Configuration
INCREMENT_KEY = "ipi_defective_time_corrected_last_date"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ Main Incremental Logic
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def incremental_ipi_defective_time_correction(**context):
    """
    Incremental ì‘ì—…: ì „ì¼ ë°ì´í„° ì²˜ë¦¬
    """
    pg_prod = PostgresHelper(conn_id=PRODUCTION_POSTGRES_CONN_ID)
    pg_quality = PostgresHelper(conn_id=QUALITY_POSTGRES_CONN_ID)
    
    # ê³µìš© Variableì—ì„œ ë§ˆì§€ë§‰ ì²˜ë¦¬ì¼ì„ ì½ê³ , ê·¸ ë‹¤ìŒë‚ ì„ ì²˜ë¦¬ ëŒ€ìƒìœ¼ë¡œ ì„¤ì •
    last_date_str = Variable.get(INCREMENT_KEY, default_var=None)
    # UTC ê¸°ì¤€ ë‚ ì§œ ê³„ì‚° (ë‚ ì§œ ë¹„êµë¥¼ ìœ„í•´ ì‹œê°„ ì œê±°)
    now_utc = datetime.utcnow()
    today_minus_1 = (now_utc - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)

    if last_date_str:
        try:
            last_date = datetime.strptime(last_date_str, '%Y-%m-%d')
            last_date = last_date.replace(hour=0, minute=0, second=0, microsecond=0)
        except Exception:
            # í˜•ì‹ ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ today-1ë¡œ ì¬ì„¤ì •
            last_date = today_minus_1 - timedelta(days=1)
        target_date = last_date + timedelta(days=1)
    else:
        # Variable ë¯¸ì„¤ì • ì‹œ today-1ì„ ì²˜ë¦¬
        target_date = today_minus_1

    # today-1ì„ ìƒí•œìœ¼ë¡œ ìº¡ (ê°™ê±°ë‚˜ ì‘ìœ¼ë©´ ì²˜ë¦¬)
    if target_date > today_minus_1:
        logging.info(f"âœ… ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. ì²˜ë¦¬í•  ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤ (Variable ê¸°ì¤€).")
        logging.info(f"   Variable last_date: {last_date_str}")
        logging.info(f"   target_date: {target_date.strftime('%Y-%m-%d')}")
        logging.info(f"   today_minus_1: {today_minus_1.strftime('%Y-%m-%d')}")
        return {"status": "up_to_date", "last_date": last_date_str or None}

    # ëŒ€ìƒ ì¼ì 00:00:00 ~ 23:59:59
    start_time = target_date.strftime('%Y-%m-%d')
    end_time = target_date.strftime('%Y-%m-%d')
    
    logging.info(f"\n{'='*60}")
    logging.info(f"ğŸš€ IPI Defective Time Correction Incremental ì‹œì‘")
    logging.info(f"{'='*60}")
    logging.info(f"ğŸ“… ì²˜ë¦¬ ë‚ ì§œ: {start_time}")
    logging.info(f"â±ï¸  Delta Threshold: {DELTA_SEC_THRESHOLD}ì´ˆ")
    
    try:
        # ë°ì´í„° ì¶”ì¶œ
        mc_df = extract_mc_data(pg_prod, start_time, end_time)
        ipi_df = extract_ipi_data(pg_quality, start_time, end_time)
        
        if len(mc_df) == 0:
            logging.warning("âš ï¸ MC ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            update_variable(INCREMENT_KEY, start_time)
            return {"status": "no_data", "message": "MC ë°ì´í„° ì—†ìŒ", "date": start_time}
        
        if len(ipi_df) == 0:
            logging.warning("âš ï¸ IPI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            update_variable(INCREMENT_KEY, start_time)
            return {"status": "no_data", "message": "IPI ë°ì´í„° ì—†ìŒ", "date": start_time}
        
        # ë¬¸ìì—´ ì •ê·œí™”
        mc_df, ipi_df = normalize_strings(mc_df, ipi_df)
        
        # ì‹œê°„ íŒŒì‹±
        mc_df, ipi_df = parse_datetimes(mc_df, ipi_df)
        
        # ì‹œê°„ ë§¤ì¹­ ë£¨í”„ ìˆ˜í–‰
        ipi_df = perform_time_matching(mc_df, ipi_df)
        
        # Delta ì´ˆê³¼ ë²”ìœ„ í•„í„°ë§
        df_normal, df_exceed = filter_by_delta_threshold(ipi_df, DELTA_SEC_THRESHOLD)
        
        # Silver í…Œì´ë¸” ì ì¬
        if len(df_normal) > 0:
            load_to_silver(pg_quality, df_normal)
            logging.info(f"âœ… Incremental ì™„ë£Œ: {start_time} ({len(df_normal):,} rows)")
        else:
            logging.info(f"âš ï¸ Incremental ë°ì´í„° ì—†ìŒ: {start_time}")
        
        # Variable ì—…ë°ì´íŠ¸
        update_variable(INCREMENT_KEY, start_time)
        
        logging.info(f"\n{'='*60}")
        logging.info(f"âœ… Incremental ì™„ë£Œ")
        logging.info(f"{'='*60}")
        logging.info(f"ğŸ“… ì²˜ë¦¬ ë‚ ì§œ: {start_time}")
        logging.info(f"ğŸ“Š ì›ë³¸ IPI ë°ì´í„°: {len(ipi_df):,} rows")
        logging.info(f"ğŸ“Š ì •ìƒ ë²”ìœ„ ë°ì´í„°: {len(df_normal):,} rows")
        logging.info(f"ğŸ“Š ì´ˆê³¼ ë²”ìœ„ ë°ì´í„°: {len(df_exceed):,} rows")
        logging.info(f"{'='*60}")
        
        return {
            "status": "success",
            "date": start_time,
            "original_rows": len(ipi_df),
            "normal_rows": len(df_normal),
            "exceed_rows": len(df_exceed)
        }
        
    except Exception as e:
        logging.error(f"\n{'='*60}")
        logging.error(f"âŒ Incremental ì‹¤íŒ¨: {str(e)}")
        logging.error(f"{'='*60}")
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ DAG Definition
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with DAG(
    dag_id='ipi_defective_time_correction_incremental',
    default_args=DEFAULT_ARGS,
    description='IPI Defective Time Correction Incremental - ì „ì¼ ë°ì´í„° ì ì¬',
    schedule_interval=None,  # ë§¤ì¼ ì‹¤í–‰
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['JJ', 'quality', 'IP', 'Silver Layer', 'incremental', 'IPI'],
    max_active_runs=1,
) as dag:
    
    incremental_task = PythonOperator(
        task_id='ipi_defective_time_correction_incremental',
        python_callable=incremental_ipi_defective_time_correction,
        provide_context=True,
    )
    
    incremental_task

