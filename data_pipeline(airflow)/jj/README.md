# ğŸŒ¬ï¸**Airflow Guide**

[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-2.x-017CEE?logo=apache-airflow&logoColor=white)](https://airflow.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?logo=python&logoColor=white)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white)](https://www.docker.com/)
[![Docker Compose](https://img.shields.io/badge/Docker%20Compose-Supported-2496ED?logo=docker&logoColor=white)](https://docs.docker.com/compose/)
[![Celery](https://img.shields.io/badge/Celery-Executor-37814A?logo=celery&logoColor=white)](https://docs.celeryq.dev/)
[![Flower](https://img.shields.io/badge/Flower-Monitoring-FF6B6B?logo=flower&logoColor=white)](https://flower.readthedocs.io/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This document guides you through installing Apache **Airflow** using Docker Compose.

## ğŸ“ Project Structure

```
airflow/
â”œâ”€â”€ dags/                          # DAG íŒŒì¼ ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ dbt/                       # dbt í”„ë¡œì íŠ¸ DAGs
â”‚   â”‚   â”œâ”€â”€ banbury_anomaly_detection/  # Banbury ì´ìƒ íƒì§€ í”„ë¡œì íŠ¸
â”‚   â”‚   â””â”€â”€ sample_project/        # ìƒ˜í”Œ dbt í”„ë¡œì íŠ¸
â”‚   â”œâ”€â”€ pipeline/                  # ë°ì´í„° íŒŒì´í”„ë¼ì¸ DAGs
â”‚   â”‚   â”œâ”€â”€ data_transfer/         # ë°ì´í„° ì „ì†¡ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ maintenance/           # ìœ ì§€ë³´ìˆ˜ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ ml/                    # ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ monitoring/            # ëª¨ë‹ˆí„°ë§ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ orchestration/         # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ production/            # í”„ë¡œë•ì…˜ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ quality/               # ë°ì´í„° í’ˆì§ˆ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â””â”€â”€ telemetry/             # í…”ë ˆë©”íŠ¸ë¦¬ íŒŒì´í”„ë¼ì¸
â”‚   â””â”€â”€ sample/                    # ìƒ˜í”Œ DAGs
â”œâ”€â”€ db/                            # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ data_quality/              # ë°ì´í„° í’ˆì§ˆ ê´€ë ¨ SQL
â”‚   â”œâ”€â”€ maintenance/               # ìœ ì§€ë³´ìˆ˜ ê´€ë ¨ SQL
â”‚   â”œâ”€â”€ monitoring/                 # ëª¨ë‹ˆí„°ë§ ê´€ë ¨ SQL
â”‚   â”œâ”€â”€ production/                # í”„ë¡œë•ì…˜ ê´€ë ¨ SQL
â”‚   â”œâ”€â”€ quality/                   # í’ˆì§ˆ ê´€ë ¨ SQL
â”‚   â””â”€â”€ telemetry/                 # í…”ë ˆë©”íŠ¸ë¦¬ ê´€ë ¨ SQL
â”œâ”€â”€ scripts/                       # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ install_pytorch_docker.sh  # PyTorch ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ install_tensorflow_docker.sh  # TensorFlow ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ monitor_performance.sh     # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ quick_restart.sh           # ë¹ ë¥¸ ì¬ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ configs/                       # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ airflow.cfg                # Airflow ì„¤ì • íŒŒì¼
â”œâ”€â”€ plugins/                       # ì»¤ìŠ¤í…€ í”ŒëŸ¬ê·¸ì¸
â”‚   â”œâ”€â”€ hooks/                     # ì»¤ìŠ¤í…€ hooks
â”‚   â””â”€â”€ models/                    # ì»¤ìŠ¤í…€ models
â”œâ”€â”€ auths/                         # ì¸ì¦ ê´€ë ¨ ì„¤ì •
â”œâ”€â”€ models/                        # ëª¨ë¸ íŒŒì¼
â”œâ”€â”€ oracle/                        # Oracle ê´€ë ¨ ì„¤ì •
â”œâ”€â”€ docs/                          # ë¬¸ì„œ
â”œâ”€â”€ Anomaly-Transformer/           # Anomaly Transformer ëª¨ë¸
â”œâ”€â”€ docker-compose.yml             # Docker Compose ì„¤ì •
â”œâ”€â”€ requirements.txt               # Python íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â”œâ”€â”€ README.md                      # ì´ íŒŒì¼
â”œâ”€â”€ RESTART_GUIDE.md               # ì¬ì‹œì‘ ê°€ì´ë“œ
â””â”€â”€ PERFORMANCE_MONITORING.md      # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ
```

## ğŸ“š Related Documentation

- **[RESTART_GUIDE.md](./RESTART_GUIDE.md)**: Airflow ì„¤ì • ë³€ê²½ í›„ ì•ˆì „í•œ ì¬ì‹œì‘ ê°€ì´ë“œ
- **[PERFORMANCE_MONITORING.md](./PERFORMANCE_MONITORING.md)**: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” ê°€ì´ë“œ
- **[dags/dbt/README.md](./dags/dbt/README.md)**: dbt í”„ë¡œì íŠ¸ ê´€ë¦¬ ê°€ì´ë“œ

## âš™ï¸ Prerequisites

* Docker and Docker Compose installed.
* Basic terminal command knowledge.
* `.env` file configured with necessary environment variables.

## ğŸ› ï¸**Installation Steps**
### Step 1: Prepare for Installation
 1. ğŸ“ Verify `docker-compose.yml` File Location
    * Ensure you are in the directory containing the `docker-compose.yml` file.
 2. ğŸ“„ Check `.env` File
    * Verify that all required environment variables are correctly set in the `.env` file.
 3. ğŸ“‚ Create Mount Directories
    * Run the following command to create necessary directories:
    ```
    mkdir -p ./dags ./logs ./plugins
    ```
### Step 2: Initialize Airflow
 1. âš™ï¸ Initialize Airflow Environment
    * Run the following command to set up the Airflow database:
    ```
    docker compose up airflow-init
    ```
 2. ğŸš€ Start Airflow Services
    * Start WebServer, Scheduler, Triggerer, and optionally Worker and CLI:
    ```
    docker compose up -d
    ```
 3. ğŸŒ¸ Start Flower (Optional)
    * To monitor the Celery Executor using Flower UI:
    ```
    docker compose up -d airflow-flower
    ```
### Step 3: Generate Security Keys
 1. ğŸ” Access Scheduler or WebServer Container
    * Run the following command to access the container:
    ```
    docker exec -it <airflow-scheduler-container> bash
    ```
 2. ğŸ”‘ Generate Keys Using Python
    * Fernet Key:
    ```
    from cryptography.fernet import Fernet
    FERNET_KEY = Fernet.generate_key().decode()
    print(FERNET_KEY)
    ```
    * Secret Key:
    ```
    import os
    print(os.urandom(16).hex())
    ```
 3. âœï¸ Update `.env` File
    * Add the generated keys to the `.env` file
    ```
    AIRFLOW__CORE__FERNET_KEY=<Generated-Fernet-Key>
    AIRFLOW__WEBSERVER__SECRET_KEY=<Generated-Secret-Key>
    ```
 4. â™»ï¸ Apply Security Keys
    * Rebuild and restart the containers:
    ```
    docker compose up --build --force-recreate -d airflow-init
    docker compose up --build --force-recreate -d
    docker compose up --build --force-recreate -d airflow-flower
    ```
 5. â¬†ï¸ worker Scale Up
    * Rebuild and Created the containers:
    ```
    docker-compose up -d --scale airflow-worker={i} airflow-worker
    ```

### Step 4: Verify Installation
 1. ğŸ“‹ Check Container Status
    * Ensure all containers are running
    ```
    docker ps
    ```
 2. ğŸŒ Access Airflow WebServer UI
    * Open http://localhost:8080
 3. ğŸŒ¸ (Optional) Access Flower UI
    * Open http://localhost:5555

## ğŸ“ƒ License
This project is licensed under the MIT License.

## ğŸ¤ Contributing
Contributions are welcome! Feel free to open issues or submit pull requests. 

## ğŸš€ Quick Start Scripts

### Performance Monitoring
```bash
./scripts/monitor_performance.sh
```

### Quick Restart
```bash
./scripts/quick_restart.sh
```

### Install ML Libraries
```bash
# PyTorch ì„¤ì¹˜
./scripts/install_pytorch_docker.sh

# TensorFlow ì„¤ì¹˜
./scripts/install_tensorflow_docker.sh
```

## ğŸ“Š Key Features

- **Multi-Project dbt Support**: ì—¬ëŸ¬ dbt í”„ë¡œì íŠ¸ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬
- **Pipeline Orchestration**: ë°ì´í„° ì „ì†¡, ìœ ì§€ë³´ìˆ˜, ML, ëª¨ë‹ˆí„°ë§ ë“± ë‹¤ì–‘í•œ íŒŒì´í”„ë¼ì¸ ì§€ì›
- **Performance Monitoring**: Flower UI ë° ì»¤ìŠ¤í…€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- **Scalable Architecture**: Celery Executorë¥¼ í†µí•œ ìˆ˜í‰ í™•ì¥ ì§€ì›
- **Custom Plugins**: ì»¤ìŠ¤í…€ hooksì™€ modelsë¥¼ í†µí•œ í™•ì¥ì„±

## âœ… Conclusion
This guide helps you set up **Airflow** with **Flower** using Docker Compose. This setting allows you to efficiently manage **work flow management** and **data collection**.