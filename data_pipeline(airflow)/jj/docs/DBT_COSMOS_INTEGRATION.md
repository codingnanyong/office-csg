# dbtì™€ Astronomer Cosmos í†µí•© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” í˜„ì¬ ìš´ì˜ ì¤‘ì¸ Airflow í™˜ê²½ì— **dbt (Data Build Tool)**ì™€ **Astronomer Cosmos**ë¥¼ í†µí•©í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

### dbtë€?
- ë°ì´í„° ë³€í™˜(Transform) ì‘ì—…ì„ SQL ê¸°ë°˜ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬
- ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ì—ì„œ ELT íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì— ì‚¬ìš©
- ëª¨ë¸, í…ŒìŠ¤íŠ¸, ë¬¸ì„œí™” ê¸°ëŠ¥ ì œê³µ

### Astronomer Cosmosë€?
- Airflowì™€ dbtë¥¼ í†µí•©í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬
- dbt í”„ë¡œì íŠ¸ë¥¼ Airflow DAGë¡œ ìë™ ë³€í™˜
- dbt ëª¨ë¸ì„ Airflow íƒœìŠ¤í¬ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ í•´ì¤Œ

## ğŸ’° ë¹„ìš© ì •ë³´

### âœ… ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)
- **dbt Core**: ì™„ì „ ë¬´ë£Œ ì˜¤í”ˆì†ŒìŠ¤
- **Astronomer Cosmos**: ì™„ì „ ë¬´ë£Œ ì˜¤í”ˆì†ŒìŠ¤ (Apache 2.0 ë¼ì´ì„ ìŠ¤)

### ğŸ’³ ìœ ë£Œ ì˜µì…˜ (ì„ íƒì‚¬í•­)
- **dbt Cloud**: dbt Labsì˜ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ (ìœ ë£Œ, ì„ íƒì‚¬í•­)
- **Astronomer Platform**: Astronomerì˜ ê´€ë¦¬í˜• Airflow ì„œë¹„ìŠ¤ (ìœ ë£Œ, ì„ íƒì‚¬í•­)

**ê²°ë¡ **: ê¸°ë³¸ í†µí•©ì€ **100% ë¬´ë£Œ**ì…ë‹ˆë‹¤. ìì²´ í˜¸ìŠ¤íŒ… í™˜ê²½ì—ì„œëŠ” ì¶”ê°€ ë¹„ìš©ì´ ì—†ìŠµë‹ˆë‹¤.

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1ë‹¨ê³„: requirements.txt ì—…ë°ì´íŠ¸

`requirements.txt`ì— ë‹¤ìŒ íŒ¨í‚¤ì§€ê°€ ì¶”ê°€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

```txt
# dbt ë° Cosmos í†µí•©
astronomer-cosmos>=1.0.0
dbt-core>=1.5.0
dbt-postgres>=1.5.0  # PostgreSQL ì‚¬ìš© ì‹œ
# ë˜ëŠ” ë‹¤ë¥¸ ì–´ëŒ‘í„°:
# dbt-snowflake>=1.5.0  # Snowflake ì‚¬ìš© ì‹œ
# dbt-bigquery>=1.5.0   # BigQuery ì‚¬ìš© ì‹œ
# dbt-redshift>=1.5.0   # Redshift ì‚¬ìš© ì‹œ
```

### 2ë‹¨ê³„: dbt í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

Airflowì˜ `dags` ë””ë ‰í† ë¦¬ ë‚´ì— dbt í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

```bash
cd /home/user/apps/airflow/dags
mkdir -p dbt/my_dbt_project
cd dbt/my_dbt_project
```

ë˜ëŠ” Airflow ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ:

```bash
docker exec -it airflow-scheduler bash
cd /opt/airflow/dags
mkdir -p dbt/my_dbt_project
cd dbt/my_dbt_project
dbt init my_dbt_project
```

### 3ë‹¨ê³„: dbt í”„ë¡œì íŠ¸ ì„¤ì •

`dbt/my_dbt_project/dbt_project.yml` íŒŒì¼ì„ ìƒì„±/ìˆ˜ì •:

```yaml
name: 'my_dbt_project'
version: '1.0.0'
config-version: 2

profile: 'my_dbt_project'

model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target"
clean-targets:
  - "target"
  - "dbt_packages"

models:
  my_dbt_project:
    +materialized: view
```

`dbt/my_dbt_project/profiles.yml` íŒŒì¼ ìƒì„±:

```yaml
my_dbt_project:
  outputs:
    dev:
      type: postgres
      host: "{{ env_var('DBT_HOST', '10.10.100.80') }}"  # ì‹¤ì œ ë°ì´í„° ì €ì¥ì†Œ í˜¸ìŠ¤íŠ¸
      port: "{{ env_var('DBT_PORT', '5432') }}"
      user: "{{ env_var('DBT_USER', 'your_user') }}"
      password: "{{ env_var('DBT_PASSWORD', 'your_password') }}"
      dbname: "{{ env_var('DBT_DATABASE', 'telemetry') }}"  # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
      schema: dbt  # dbtê°€ ì‚¬ìš©í•  ìŠ¤í‚¤ë§ˆ
    prod:
      type: postgres
      host: "{{ env_var('DBT_HOST', '10.10.100.80') }}"
      port: "{{ env_var('DBT_PORT', '5432') }}"
      user: "{{ env_var('DBT_USER', 'your_user') }}"
      password: "{{ env_var('DBT_PASSWORD', 'your_password') }}"
      dbname: "{{ env_var('DBT_DATABASE', 'telemetry') }}"
      schema: dbt
  target: dev
```

**âš ï¸ ì¤‘ìš”**: 
- `host`: **ì‹¤ì œ ë°ì´í„° ì €ì¥ì†Œ**ì˜ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ (ì˜ˆ: `10.10.100.80` ë˜ëŠ” ì™¸ë¶€ DB)
- `dbname`: **ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„** (ì˜ˆ: `telemetry`, `monitoring` ë“±)
- `airflow-postgres`ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ `host: postgres`ë¡œ ì„¤ì •í•˜ë˜, ì¼ë°˜ì ìœ¼ë¡œëŠ” ì‹¤ì œ ë°ì´í„° ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤

### 4ë‹¨ê³„: Airflow DAG ì‘ì„±

`dags/dbt_dag_example.py` íŒŒì¼ ìƒì„±:

```python
from datetime import datetime
from airflow import DAG
from airflow.utils.task_group import TaskGroup
from cosmos import DbtTaskGroup, ProjectConfig, ProfileConfig, ExecutionConfig
from cosmos.profiles import PostgresUserPasswordProfileMapping

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
}

# Profile ì„¤ì • (PostgreSQL ì‚¬ìš© ì˜ˆì‹œ)
profile_config = ProfileConfig(
    profile_name="my_dbt_project",
    target_name="dev",
    profile_mapping=PostgresUserPasswordProfileMapping(
        conn_id="postgres_default",  # Airflow Connection ID
        profile_args={"schema": "dbt"}
    ),
)

# Execution ì„¤ì •
execution_config = ExecutionConfig(
    dbt_executable_path="/usr/local/bin/dbt",  # ë˜ëŠ” dbtê°€ ì„¤ì¹˜ëœ ê²½ë¡œ
)

# DAG ì •ì˜
with DAG(
    dag_id="dbt_transform_pipeline",
    default_args=default_args,
    description="dbtë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸",
    schedule_interval="@daily",
    catchup=False,
    tags=["dbt", "transform"],
) as dag:
    
    # dbt TaskGroup ìƒì„±
    dbt_transform = DbtTaskGroup(
        group_id="dbt_transform",
        project_config=ProjectConfig(
            dbt_project_path="/opt/airflow/dags/dbt/my_dbt_project",
        ),
        profile_config=profile_config,
        execution_config=execution_config,
        operator_args={
            "install_deps": True,  # dbt ì˜ì¡´ì„± ìë™ ì„¤ì¹˜
        },
    )
```

### 5ë‹¨ê³„: Airflow Connection ì„¤ì •

**âš ï¸ ì¤‘ìš”**: dbtëŠ” **ì‹¤ì œ ë°ì´í„°ê°€ ì €ì¥ëœ ë°ì´í„°ë² ì´ìŠ¤**ì— ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤. 
- `airflow-postgres`ëŠ” Airflow ë©”íƒ€ë°ì´í„°ìš©ì´ë¯€ë¡œ ì¼ë°˜ì ìœ¼ë¡œ dbt ì‘ì—… ëŒ€ìƒì´ **ì•„ë‹™ë‹ˆë‹¤**
- ì‚¬ìš©ìê°€ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” **ì‹¤ì œ ë°ì´í„° ì €ì¥ì†Œ** ë¥¼ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤

Airflow UIì—ì„œ Connectionì„ ì„¤ì •í•˜ê±°ë‚˜ CLIë¡œ ì„¤ì •:

```bash
# ì˜ˆì‹œ: ì‹¤ì œ ë°ì´í„° ì €ì¥ì†Œ ì—°ê²° (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
docker exec -it airflow-webserver airflow connections add 'postgres_default' \
    --conn-type 'postgres' \
    --conn-host '10.10.100.80' \
    --conn-schema 'telemetry' \
    --conn-login 'your_user' \
    --conn-password 'your_password' \
    --conn-port 5432
```

ë˜ëŠ” Airflow UIì—ì„œ:
1. Admin â†’ Connections
2. `+` ë²„íŠ¼ í´ë¦­
3. Connection ID: `postgres_default` (ë˜ëŠ” ì›í•˜ëŠ” ì´ë¦„)
4. Connection Type: `Postgres`
5. **ì‹¤ì œ ë°ì´í„° ì €ì¥ì†Œ ì •ë³´ ì…ë ¥**:
   - **Host**: ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ í˜¸ìŠ¤íŠ¸ (ì˜ˆ: `10.10.100.80` ë˜ëŠ” ì™¸ë¶€ DB ì£¼ì†Œ)
   - **Schema**: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì˜ˆ: `telemetry`, `monitoring` ë“±)
   - **Login**: ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©ìëª…
   - **Password**: ë°ì´í„°ë² ì´ìŠ¤ ë¹„ë°€ë²ˆí˜¸
   - **Port**: ë°ì´í„°ë² ì´ìŠ¤ í¬íŠ¸ (ì¼ë°˜ì ìœ¼ë¡œ `5432`)

**ì°¸ê³ **: 
- `airflow-postgres`ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Hostë¥¼ `postgres` (docker-compose ì„œë¹„ìŠ¤ ì´ë¦„)ë¡œ ì„¤ì •
- í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œëŠ” ì‹¤ì œ ë°ì´í„° ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤

### 6ë‹¨ê³„: Docker Compose ì—…ë°ì´íŠ¸ (ì„ íƒì‚¬í•­)

dbt í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ë³¼ë¥¨ì— ì¶”ê°€í•˜ë ¤ë©´ `docker-compose.yml`ì˜ volumes ì„¹ì…˜ì— ì¶”ê°€:

```yaml
volumes:
  - ./dags:/opt/airflow/dags
  - ./dags/dbt:/opt/airflow/dags/dbt  # dbt í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬
```

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### ê°„ë‹¨í•œ dbt ëª¨ë¸ ì˜ˆì‹œ

`dbt/my_dbt_project/models/staging/stg_customers.sql`:

```sql
{{ config(materialized='view') }}

select
    id,
    name,
    email,
    created_at
from {{ source('raw', 'customers') }}
where is_active = true
```

`dbt/my_dbt_project/models/marts/dim_customers.sql`:

```sql
{{ config(materialized='table') }}

select
    id as customer_id,
    name as customer_name,
    email,
    created_at as customer_since
from {{ ref('stg_customers') }}
```

### DAGì—ì„œ íŠ¹ì • ëª¨ë¸ë§Œ ì‹¤í–‰

```python
dbt_transform = DbtTaskGroup(
    group_id="dbt_transform",
    project_config=ProjectConfig(
        dbt_project_path="/opt/airflow/dags/dbt/my_dbt_project",
    ),
    profile_config=profile_config,
    execution_config=execution_config,
    select=["models/staging/*"],  # íŠ¹ì • ê²½ë¡œì˜ ëª¨ë¸ë§Œ ì‹¤í–‰
    # ë˜ëŠ”
    # select=["tag:staging"],  # íƒœê·¸ë¡œ í•„í„°ë§
)
```

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### ì»¤ìŠ¤í…€ dbt ì‹¤í–‰ ê²½ë¡œ

`execution_config`ì—ì„œ dbt ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ ì§€ì •:

```python
execution_config = ExecutionConfig(
    dbt_executable_path="/usr/local/bin/dbt",
    # ë˜ëŠ” Python íŒ¨í‚¤ì§€ë¡œ ì„¤ì¹˜ëœ ê²½ìš°
    # dbt_executable_path="dbt",
)
```

### í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©

`.env` íŒŒì¼ì— dbt ê´€ë ¨ ë³€ìˆ˜ ì¶”ê°€:

```env
DBT_PROJECT_PATH=/opt/airflow/dags/dbt/my_dbt_project
DBT_PROFILE_NAME=my_dbt_project
DBT_TARGET=dev
```

### ë‹¤ë¥¸ ë°ì´í„°ë² ì´ìŠ¤ ì–´ëŒ‘í„° ì‚¬ìš©

PostgreSQL ì™¸ ë‹¤ë¥¸ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© ì‹œ:

```python
# Snowflake ì˜ˆì‹œ
from cosmos.profiles import SnowflakeUserPasswordProfileMapping

profile_config = ProfileConfig(
    profile_name="my_dbt_project",
    target_name="dev",
    profile_mapping=SnowflakeUserPasswordProfileMapping(
        conn_id="snowflake_default",
        profile_args={"schema": "dbt", "database": "analytics"}
    ),
)
```

ê·¸ë¦¬ê³  `requirements.txt`ì— í•´ë‹¹ ì–´ëŒ‘í„° ì¶”ê°€:
```txt
dbt-snowflake>=1.5.0
```

## âœ… ê²€ì¦ ë° í…ŒìŠ¤íŠ¸

### 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸

```bash
docker exec -it airflow-scheduler pip list | grep -E "cosmos|dbt"
```

### 2. dbt í”„ë¡œì íŠ¸ ê²€ì¦

```bash
docker exec -it airflow-scheduler bash
cd /opt/airflow/dags/dbt/my_dbt_project
dbt debug
dbt parse
```

### 3. DAG ë¡œë“œ í™•ì¸

Airflow UIì—ì„œ DAGê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸:
- DAG ëª©ë¡ì— `dbt_transform_pipeline`ì´ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸
- DAGë¥¼ í´ë¦­í•˜ì—¬ íƒœìŠ¤í¬ êµ¬ì¡° í™•ì¸

## ğŸ› ë¬¸ì œ í•´ê²°

### ë¬¸ì œ: dbt ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
**í•´ê²°**: `execution_config`ì˜ `dbt_executable_path` í™•ì¸ ë˜ëŠ” `install_deps=True` ì„¤ì •

### ë¬¸ì œ: Connection ì˜¤ë¥˜
**í•´ê²°**: Airflow Connectionì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸

### ë¬¸ì œ: ëª¨ë¸ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
**í•´ê²°**: `dbt_project.yml`ê³¼ `profiles.yml` ì„¤ì • í™•ì¸

## ğŸ“š ì°¸ê³  ìë£Œ

- [Astronomer Cosmos ê³µì‹ ë¬¸ì„œ](https://astronomer.github.io/astronomer-cosmos/)
- [dbt Core ë¬¸ì„œ](https://docs.getdbt.com/docs/introduction)
- [Airflow dbt í†µí•© ê°€ì´ë“œ](https://airflow.apache.org/docs/apache-airflow-providers-dbt-cloud/stable/index.html)

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. `requirements.txt` ì—…ë°ì´íŠ¸
2. dbt í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
3. ìƒ˜í”Œ DAG ìƒì„± ë° í…ŒìŠ¤íŠ¸
4. ì‹¤ì œ ë°ì´í„° ëª¨ë¸ ê°œë°œ

